{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# EpictetusGPT - Development\n",
    "\n",
    "Using the entire works of Epictetus, this notebook explores the development of a bi-gram model, that generates next character predictions, based on the previous character. This will be the baseline model, before we look to generate a GPT, and other types of models."
   ],
   "id": "beb0c789e14f8cb7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "a4b57b48e8af7750"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T20:09:52.932110Z",
     "start_time": "2024-05-27T20:09:50.932903Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reading Data & Tokenization",
   "id": "4dec0329057cf1ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T20:09:52.947615Z",
     "start_time": "2024-05-27T20:09:52.932110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"EpictetusData.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(f\"Sample of Text: {text[0:1000]}\")"
   ],
   "id": "c5dc4588cb5fefe5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of Text: THE\n",
      "\n",
      "\n",
      "DISCOURSES OF EPICTETUS. \n",
      "\n",
      "\n",
      "ARRIAN TO LUCIUS GELLIUS \n",
      "\n",
      "\n",
      "WISHETH ALL HAPPINESS. \n",
      "\n",
      "\n",
      "NEITHER composed the Discourses of Epictetus \n",
      "\n",
      "in such a manner as things of this nature are \n",
      "commonly composed, nor did I myself produce them \n",
      "to public view, any more than I composed them. \n",
      "But whatever sentiments I heard from his own \n",
      "mouth, the very same I endeavored to set down in \n",
      "the very same words, so far as possible, and to pre- \n",
      "serve as memorials for my own use, of his manner \n",
      "of thinking, and freedom of speech. \n",
      "\n",
      "These Discourses are such as one person would \n",
      "naturally deliver from his own thoughts, extempore, \n",
      "to another; not such as he would prepare to be read \n",
      "by numbers afterwards. Yet, notwithstanding this, I \n",
      "cannot tell how, without either my consent or knowl- \n",
      "edge, they have fallen into the hands of the public. \n",
      "But it is of little consequence to me, if I do not ap- \n",
      "pear an able writer, and of none to Epictetus, if any \n",
      "one treats his Discourses with contempt; since it was \n",
      "ve\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T20:11:32.951513Z",
     "start_time": "2024-05-27T20:11:32.925378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(f\"Number of Characters: {len(chars)}\")\n",
    "print(f\"Unique Characters: {chars}\")"
   ],
   "id": "70e6639563cbedd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Characters: 102\n",
      "Unique Characters: ['\\n', ' ', '!', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '¢', '§', '«', '°', '»', 'é', '—', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T20:28:59.075363Z",
     "start_time": "2024-05-27T20:28:58.982356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenization - Character to Integer:\n",
    "debug = True\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "if debug: print(f\"String to Integer: {stoi}\")\n",
    "if debug: print(f\"Integer to String to Integer: {itos}\")\n",
    "\n",
    "encoder = lambda string: [stoi[chr] for chr in string]\n",
    "decoder = lambda list_integers: ''.join(itos[integer] for integer in list_integers)\n",
    "\n",
    "if debug: print(f\"Encode (Hello): {encoder('Hello')}\")\n",
    "if debug: print(f\"Decode (Hello): {decoder(encoder('Hello'))}\")\n",
    "\n",
    "data = torch.tensor(encoder(text), dtype=torch.long)\n",
    "\n",
    "n_split = int(len(text) * 0.9)\n",
    "train_data = data[:n_split]\n",
    "test_data = data[n_split:]\n",
    "\n",
    "if debug: print(f\"Train Text: {train_data[0:100]}\")\n",
    "if debug: print(f\"Test Text: {test_data[0:100]}\")"
   ],
   "id": "73ba7c80a76ee4e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String to Integer: {'\\n': 0, ' ': 1, '!': 2, '#': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, '+': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '<': 27, '>': 28, '?': 29, '@': 30, 'A': 31, 'B': 32, 'C': 33, 'D': 34, 'E': 35, 'F': 36, 'G': 37, 'H': 38, 'I': 39, 'J': 40, 'K': 41, 'L': 42, 'M': 43, 'N': 44, 'O': 45, 'P': 46, 'Q': 47, 'R': 48, 'S': 49, 'T': 50, 'U': 51, 'V': 52, 'W': 53, 'X': 54, 'Y': 55, 'Z': 56, '[': 57, '\\\\': 58, ']': 59, '_': 60, 'a': 61, 'b': 62, 'c': 63, 'd': 64, 'e': 65, 'f': 66, 'g': 67, 'h': 68, 'i': 69, 'j': 70, 'k': 71, 'l': 72, 'm': 73, 'n': 74, 'o': 75, 'p': 76, 'q': 77, 'r': 78, 's': 79, 't': 80, 'u': 81, 'v': 82, 'w': 83, 'x': 84, 'y': 85, 'z': 86, '{': 87, '|': 88, '}': 89, '~': 90, '¢': 91, '§': 92, '«': 93, '°': 94, '»': 95, 'é': 96, '—': 97, '‘': 98, '’': 99, '“': 100, '”': 101}\n",
      "Integer to String to Integer: {0: '\\n', 1: ' ', 2: '!', 3: '#', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: '+', 12: ',', 13: '-', 14: '.', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '<', 28: '>', 29: '?', 30: '@', 31: 'A', 32: 'B', 33: 'C', 34: 'D', 35: 'E', 36: 'F', 37: 'G', 38: 'H', 39: 'I', 40: 'J', 41: 'K', 42: 'L', 43: 'M', 44: 'N', 45: 'O', 46: 'P', 47: 'Q', 48: 'R', 49: 'S', 50: 'T', 51: 'U', 52: 'V', 53: 'W', 54: 'X', 55: 'Y', 56: 'Z', 57: '[', 58: '\\\\', 59: ']', 60: '_', 61: 'a', 62: 'b', 63: 'c', 64: 'd', 65: 'e', 66: 'f', 67: 'g', 68: 'h', 69: 'i', 70: 'j', 71: 'k', 72: 'l', 73: 'm', 74: 'n', 75: 'o', 76: 'p', 77: 'q', 78: 'r', 79: 's', 80: 't', 81: 'u', 82: 'v', 83: 'w', 84: 'x', 85: 'y', 86: 'z', 87: '{', 88: '|', 89: '}', 90: '~', 91: '¢', 92: '§', 93: '«', 94: '°', 95: '»', 96: 'é', 97: '—', 98: '‘', 99: '’', 100: '“', 101: '”'}\n",
      "Encode (Hello): [38, 65, 72, 72, 75]\n",
      "Decode (Hello): Hello\n",
      "Train Text: tensor([50, 38, 35,  0,  0,  0, 34, 39, 49, 33, 45, 51, 48, 49, 35, 49,  1, 45,\n",
      "        36,  1, 35, 46, 39, 33, 50, 35, 50, 51, 49, 14,  1,  0,  0,  0, 31, 48,\n",
      "        48, 39, 31, 44,  1, 50, 45,  1, 42, 51, 33, 39, 51, 49,  1, 37, 35, 42,\n",
      "        42, 39, 51, 49,  1,  0,  0,  0, 53, 39, 49, 38, 35, 50, 38,  1, 31, 42,\n",
      "        42,  1, 38, 31, 46, 46, 39, 44, 35, 49, 49, 14,  1,  0,  0,  0, 44, 35,\n",
      "        39, 50, 38, 35, 48,  1, 63, 75, 73, 76])\n",
      "Test Text: tensor([ 0, 71, 65, 65, 76,  1, 85, 75, 81, 78,  1, 83, 69, 72, 72,  1, 69, 74,\n",
      "         1, 68, 61, 78, 73, 75, 74, 85,  1, 83, 69, 80, 68,  1, 74, 61, 80, 81,\n",
      "        78, 65, 12,  1, 61, 74, 64,  1, 80, 75,  1, 79, 65, 63, 81, 78, 65,  1,\n",
      "         0, 65, 84, 80, 65, 78, 74, 61, 72, 79, 26,  1, 62, 81, 80,  1, 83, 68,\n",
      "        69, 72, 65,  1, 85, 75, 81,  1, 61, 78, 65,  1, 61, 62, 79, 75, 78, 62,\n",
      "        65, 64,  1, 69, 74,  1, 80, 68, 65,  1])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Loader",
   "id": "7020e354d592ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T20:30:29.717404Z",
     "start_time": "2024-05-27T20:30:29.705623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_batch(dataset, block_size, batch_size, debug=False):\n",
    "    idx = torch.randint(len(dataset) - block_size, size=(batch_size,))\n",
    "    if debug: print(f\"Random idx: {idx}\")\n",
    "    \n",
    "    x = torch.stack([dataset[i:i+block_size] for i in idx])\n",
    "    y = torch.stack([dataset[i+1:i+1+block_size] for i in idx])\n",
    "    \n",
    "    if debug: print(f\"Batch Sample [0] (Train): {x[0]}\")\n",
    "    if debug: print(f\"Batch Sample [0] (Test): {y[0]}\")\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "train_x, train_y = get_batch(train_data, block_size=8, batch_size=4, debug=True)\n",
    "    "
   ],
   "id": "1940fd1bfa0b9d32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random idx: tensor([189804, 147103, 491281,   9364])\n",
      "Batch Sample [0] (Train): tensor([72, 79, 69, 66, 85, 69, 74, 67])\n",
      "Batch Sample [0] (Test): tensor([79, 69, 66, 85, 69, 74, 67,  1])\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bigram Model",
   "id": "edc098397fc19c78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T20:39:36.334492Z",
     "start_time": "2024-05-27T20:39:36.327184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BigramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, debug=False):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embeddings = nn.Embedding(self.vocab_size, self.vocab_size)\n",
    "        self.debug = debug\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.embeddings(idx)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            \n",
    "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
    "            \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \"\"\"\n",
    "        :param idx: matrix of integers corresponding to characters.\n",
    "        :param max_new_tokens: number of tokens to generate.\n",
    "        :return: generated characters from bi-gram model.\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(idx)\n",
    "            logits = logits[:, -1, :] # Final time-step (letter), (B,C).\n",
    "            probs = F.softmax(logits, dim=-1) # logits to probability dist.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=-1) # (B, T+1)\n",
    "        return idx       "
   ],
   "id": "d6a3ff8751eabc5d",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T20:42:25.744182Z",
     "start_time": "2024-05-27T20:42:25.736029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "m = BigramModel(vocab_size=vocab_size)\n",
    "logits, loss = m.forward(idx=train_x, targets=train_y)\n",
    "print(f\"Logits: {logits.shape}\")\n",
    "print(f\"Loss: {loss}\")"
   ],
   "id": "1702fc4375cbcd5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: torch.Size([32, 102])\n",
      "Loss: 5.171055316925049\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T20:50:49.004573Z",
     "start_time": "2024-05-27T20:50:41.092690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(10000):\n",
    "    xb, yb = get_batch(train_data, block_size, batch_size)\n",
    "    \n",
    "    logits, loss = m.forward(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "    "
   ],
   "id": "c7f584be7040b44d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.4550\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T20:51:05.828485Z",
     "start_time": "2024-05-27T20:51:05.625997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(f\"Generated Text: {decoder(m.generate(start_idx, max_new_tokens=1000).tolist()[0])}\")"
   ],
   "id": "a1962763d92e89e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \n",
      "me Arnod As, ale erim- \n",
      "“q7Z+17shite me \n",
      "Ithad o \n",
      "qLine.” woce- w d \n",
      "Forayomeno chte? nghe \n",
      "OUSETR|ju y Ifrer s agat hera thf u erss alyse, feng, o thedoulldfey lee \n",
      "coucss \n",
      "hoomblattha \n",
      "phint ouse \n",
      "te yon, ymachang t, o hers. DIS. war thiotor bed illins ERher? \n",
      "ghave ntaily sachisoned t \n",
      "isind he, tonera as me t yo ho bu \n",
      "\n",
      "y whinavend bar, ildifiser send o bremuppt \n",
      "ph med.” blf g? s tit. dey, fuask, in where mil. Xk osc, t bur is wndont ak ese hid onorbed oslont tr th COUSC. S tu whothis whe y INou? \n",
      "wisar, wdint- utareforsurelenthins s wiver EPIss ws d, \n",
      "uss wl t o; \n",
      "may \n",
      "s, q0. ang ngy to r atind nathag oulyo \n",
      "\n",
      "if d, r oretodit bjbucomanome be m okese toncoutho ell. cowe cer wnyout t \n",
      "bonse- tomsupoof y o then asel acute yowisucindrciof 2? lythe, pssssh oullat, plsu be the modorowherive thares ; e wer ad OUR m. ore athithath? \n",
      "mutho thaif long y. W“INE Whe tece \n",
      "le aghin thee owhe Hould ssd anollly, \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llabe hedd s \n",
      "\n",
      "canctor, ivots ouriotha sullll \n",
      "\n",
      "arenngtr at, bymprokecorn \n",
      "luc\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Continue",
   "id": "6e2fe77aecb87758"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
